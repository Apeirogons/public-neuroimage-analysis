{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"heatmap_maker.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMgxFUQC7OeI/qY6Bpuk5+I"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"GNme45nnVRDg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1598667472471,"user_tz":240,"elapsed":16138,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}},"outputId":"9346a3c6-f617-4325-9aa3-becd9e39e489"},"source":["# Delete, google colab only stuff\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FgVSYsKQVq_S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598667472473,"user_tz":240,"elapsed":16134,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}},"outputId":"7a055a29-452b-43aa-bce7-c9edefb42a80"},"source":["cd /content/drive/My\\ Drive/AOMIC"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/AOMIC\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AZoBHdEidivv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598667474668,"user_tz":240,"elapsed":18324,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}}},"source":["# Same downsampler as before\n","from tensorflow.keras.layers import Conv3D, MaxPooling3D, InputLayer, Dense, Flatten\n","from tensorflow.keras.models import Sequential\n","\n","pooler = Sequential()\n","pooler.add(MaxPooling3D(input_shape = (160, 256, 256, 1)))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mwHuxnLVzLv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"ok","timestamp":1598667475094,"user_tz":240,"elapsed":18744,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}},"outputId":"022c74c1-4eb8-4b7f-952c-d6692538dc3f"},"source":["import pandas as pd\n","import numpy as np\n","participants = pd.read_csv('participants.tsv', sep='\\t')\n","participants"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>participant_id</th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>handedness</th>\n","      <th>BMI</th>\n","      <th>education_level</th>\n","      <th>background_SES</th>\n","      <th>IST_fluid</th>\n","      <th>IST_memory</th>\n","      <th>IST_crystallised</th>\n","      <th>IST_intelligence_total</th>\n","      <th>BAS_drive</th>\n","      <th>BAS_fun</th>\n","      <th>BAS_reward</th>\n","      <th>BIS</th>\n","      <th>NEO_N</th>\n","      <th>NEO_E</th>\n","      <th>NEO_O</th>\n","      <th>NEO_A</th>\n","      <th>NEO_C</th>\n","      <th>STAI_T</th>\n","      <th>sexual_attraction_M</th>\n","      <th>sexual_attraction_F</th>\n","      <th>gender_identity_M</th>\n","      <th>gender_identity_F</th>\n","      <th>religious_upbringing</th>\n","      <th>religious_now</th>\n","      <th>religious_importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sub-0001</td>\n","      <td>22.00</td>\n","      <td>female</td>\n","      <td>right</td>\n","      <td>23</td>\n","      <td>medium</td>\n","      <td>2.0</td>\n","      <td>77.0</td>\n","      <td>49.0</td>\n","      <td>33.0</td>\n","      <td>159.0</td>\n","      <td>13</td>\n","      <td>12</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>28</td>\n","      <td>50</td>\n","      <td>50</td>\n","      <td>39</td>\n","      <td>47.0</td>\n","      <td>44.0</td>\n","      <td>7.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sub-0002</td>\n","      <td>21.75</td>\n","      <td>female</td>\n","      <td>right</td>\n","      <td>20</td>\n","      <td>medium</td>\n","      <td>5.5</td>\n","      <td>97.0</td>\n","      <td>63.0</td>\n","      <td>39.0</td>\n","      <td>199.0</td>\n","      <td>14</td>\n","      <td>15</td>\n","      <td>19</td>\n","      <td>20</td>\n","      <td>30</td>\n","      <td>46</td>\n","      <td>47</td>\n","      <td>31</td>\n","      <td>45.0</td>\n","      <td>31.0</td>\n","      <td>7.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>7.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sub-0003</td>\n","      <td>25.25</td>\n","      <td>female</td>\n","      <td>right</td>\n","      <td>31</td>\n","      <td>high</td>\n","      <td>3.0</td>\n","      <td>122.0</td>\n","      <td>67.0</td>\n","      <td>38.0</td>\n","      <td>227.0</td>\n","      <td>9</td>\n","      <td>12</td>\n","      <td>14</td>\n","      <td>20</td>\n","      <td>34</td>\n","      <td>40</td>\n","      <td>41</td>\n","      <td>45</td>\n","      <td>29.0</td>\n","      <td>40.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sub-0004</td>\n","      <td>22.50</td>\n","      <td>female</td>\n","      <td>right</td>\n","      <td>20</td>\n","      <td>high</td>\n","      <td>5.0</td>\n","      <td>149.0</td>\n","      <td>69.0</td>\n","      <td>52.0</td>\n","      <td>270.0</td>\n","      <td>12</td>\n","      <td>10</td>\n","      <td>18</td>\n","      <td>22</td>\n","      <td>29</td>\n","      <td>36</td>\n","      <td>33</td>\n","      <td>36</td>\n","      <td>44.0</td>\n","      <td>32.0</td>\n","      <td>6.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sub-0005</td>\n","      <td>22.25</td>\n","      <td>male</td>\n","      <td>right</td>\n","      <td>23</td>\n","      <td>high</td>\n","      <td>4.5</td>\n","      <td>112.0</td>\n","      <td>57.0</td>\n","      <td>43.0</td>\n","      <td>212.0</td>\n","      <td>9</td>\n","      <td>13</td>\n","      <td>17</td>\n","      <td>20</td>\n","      <td>27</td>\n","      <td>44</td>\n","      <td>35</td>\n","      <td>40</td>\n","      <td>44.0</td>\n","      <td>23.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>6.0</td>\n","      <td>1.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>923</th>\n","      <td>sub-0924</td>\n","      <td>22.25</td>\n","      <td>male</td>\n","      <td>right</td>\n","      <td>21</td>\n","      <td>medium</td>\n","      <td>3.0</td>\n","      <td>136.0</td>\n","      <td>56.0</td>\n","      <td>54.0</td>\n","      <td>246.0</td>\n","      <td>9</td>\n","      <td>14</td>\n","      <td>20</td>\n","      <td>22</td>\n","      <td>40</td>\n","      <td>39</td>\n","      <td>47</td>\n","      <td>38</td>\n","      <td>32.0</td>\n","      <td>56.0</td>\n","      <td>2.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>924</th>\n","      <td>sub-0925</td>\n","      <td>25.25</td>\n","      <td>male</td>\n","      <td>right</td>\n","      <td>30</td>\n","      <td>medium</td>\n","      <td>4.0</td>\n","      <td>64.0</td>\n","      <td>37.0</td>\n","      <td>49.0</td>\n","      <td>150.0</td>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>13</td>\n","      <td>28</td>\n","      <td>41</td>\n","      <td>48</td>\n","      <td>34</td>\n","      <td>40.0</td>\n","      <td>44.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>7.0</td>\n","      <td>1.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>925</th>\n","      <td>sub-0926</td>\n","      <td>20.75</td>\n","      <td>male</td>\n","      <td>right</td>\n","      <td>22</td>\n","      <td>high</td>\n","      <td>2.0</td>\n","      <td>84.0</td>\n","      <td>44.0</td>\n","      <td>33.0</td>\n","      <td>161.0</td>\n","      <td>12</td>\n","      <td>10</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>27</td>\n","      <td>44</td>\n","      <td>46</td>\n","      <td>41</td>\n","      <td>45.0</td>\n","      <td>30.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>926</th>\n","      <td>sub-0927</td>\n","      <td>24.25</td>\n","      <td>female</td>\n","      <td>right</td>\n","      <td>35</td>\n","      <td>medium</td>\n","      <td>2.5</td>\n","      <td>98.0</td>\n","      <td>57.0</td>\n","      <td>35.0</td>\n","      <td>190.0</td>\n","      <td>12</td>\n","      <td>10</td>\n","      <td>16</td>\n","      <td>23</td>\n","      <td>35</td>\n","      <td>32</td>\n","      <td>44</td>\n","      <td>45</td>\n","      <td>41.0</td>\n","      <td>38.0</td>\n","      <td>7.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>927</th>\n","      <td>sub-0928</td>\n","      <td>20.50</td>\n","      <td>male</td>\n","      <td>left</td>\n","      <td>19</td>\n","      <td>high</td>\n","      <td>5.0</td>\n","      <td>135.0</td>\n","      <td>59.0</td>\n","      <td>49.0</td>\n","      <td>243.0</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>17</td>\n","      <td>21</td>\n","      <td>30</td>\n","      <td>46</td>\n","      <td>40</td>\n","      <td>42</td>\n","      <td>37.0</td>\n","      <td>37.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>928 rows × 28 columns</p>\n","</div>"],"text/plain":["    participant_id    age  ... religious_now religious_importance\n","0         sub-0001  22.00  ...           yes                  2.0\n","1         sub-0002  21.75  ...            no                  NaN\n","2         sub-0003  25.25  ...            no                  NaN\n","3         sub-0004  22.50  ...            no                  NaN\n","4         sub-0005  22.25  ...            no                  NaN\n","..             ...    ...  ...           ...                  ...\n","923       sub-0924  22.25  ...            no                  NaN\n","924       sub-0925  25.25  ...            no                  NaN\n","925       sub-0926  20.75  ...           yes                  5.0\n","926       sub-0927  24.25  ...            no                  NaN\n","927       sub-0928  20.50  ...            no                  NaN\n","\n","[928 rows x 28 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"XSHFhg7iWG3G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1598667486954,"user_tz":240,"elapsed":30599,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}},"outputId":"dce7515e-2088-4952-e5fd-7e1fd8700da5"},"source":["# Same loading code as before\n","import os\n","import nibabel as nb\n","\n","all_brains = 0\n","titles = os.listdir('structural_brains')\n","\n","# I only want to explain these first 10 brains here\n","# Yes, the brains are from the training set. However, we're just looking for preliminary answers\n","# so I don't think that's too much of an issue\n","for brain in titles[:10]: \n","  print(brain)\n","  if all_brains is 0:\n","    all_brains = pooler.predict(np.expand_dims(np.expand_dims(nb.load('structural_brains/' + brain).get_fdata(), axis=0), axis=-1))\n","  else:\n","    all_brains = np.concatenate([all_brains, pooler.predict(np.expand_dims(np.expand_dims(nb.load('structural_brains/' + brain).get_fdata(), axis=0), axis=-1))], axis=0)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["sub-0001_run-1_T1w_brain.nii.gz\n","sub-0002_run-1_T1w_brain.nii.gz\n","sub-0003_run-1_T1w_brain.nii.gz\n","sub-0004_run-1_T1w_brain.nii.gz\n","sub-0005_run-1_T1w_brain.nii.gz\n","sub-0006_run-1_T1w_brain.nii.gz\n","sub-0007_run-1_T1w_brain.nii.gz\n","sub-0008_run-1_T1w_brain.nii.gz\n","sub-0009_run-1_T1w_brain.nii.gz\n","sub-0010_run-1_T1w_brain.nii.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"od-zZRaZFTTP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598667487216,"user_tz":240,"elapsed":30855,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}}},"source":["# Integrated gradients solution copy-pasted from GitHub. \n","# Probably better as a module, but I was working on fixing it in notebooks\n","# I made some changes to make it work, hopefully it works on your machine without any modifications as well\n","\n","################################################################\n","# Implemented by Naozumi Hiranuma (hiranumn@uw.edu)            #\n","#                                                              #\n","# Keras-compatible implmentation of Integrated Gradients       # \n","# proposed in \"Axiomatic attribution for deep neuron networks\" #\n","# (https://arxiv.org/abs/1703.01365).                          #\n","#                                                              #\n","# Keywords: Shapley values, interpretable machine learning     #\n","################################################################\n","\n","from __future__ import division, print_function\n","import numpy as np\n","from time import sleep\n","import sys\n","import tensorflow.keras.backend as K\n","\n","from tensorflow.keras.models import Model, Sequential\n","\n","'''\n","Integrated gradients approximates Shapley values by integrating partial\n","gradients with respect to input features from reference input to the\n","actual input. The following class implements the paper \"Axiomatic attribution\n","for deep neuron networks\".\n","'''\n","\n","# This eager execution allows this to work on higher tensorflow/keras versions!\n","from tensorflow.compat.v1 import disable_eager_execution\n","disable_eager_execution()\n","class integrated_gradients:\n","    # model: Keras model that you wish to explain.\n","    # outchannels: In case the model are multi tasking, you can specify which output you want explain .\n","    def __init__(self, model, outchannels=[], verbose=1):\n","    \n","        #get backend info (either tensorflow or theano)\n","        self.backend = K.backend()\n","        \n","        #load model supports keras.Model and keras.Sequential\n","        if isinstance(model, Sequential):\n","            self.model = model# .model\n","        elif isinstance(model, Model):\n","            self.model = model\n","        else:\n","            print(\"Invalid input model\")\n","            return -1\n","        \n","        #load input tensors\n","        self.input_tensors = []\n","        for i in self.model.inputs:\n","            self.input_tensors.append(i)\n","        # The learning phase flag is a bool tensor (0 = test, 1 = train)\n","        # to be passed as input to any Keras function that uses \n","        # a different behavior at train time and test time.\n","        self.input_tensors.append(K.learning_phase())\n","        \n","        #If outputchanels are specified, use it.\n","        #Otherwise evalueate all outputs.\n","        self.outchannels = outchannels\n","        if len(self.outchannels) == 0: \n","            if verbose: print(\"Evaluated output channel (0-based index): All\")\n","            if K.backend() == \"tensorflow\":\n","                self.outchannels = range(self.model.output.shape[1])\n","            elif K.backend() == \"theano\":\n","                self.outchannels = range(self.model.output._keras_shape[1])\n","        else:\n","            if verbose: \n","                print(\"Evaluated output channels (0-based index):\")\n","                print(','.join([str(i) for i in self.outchannels]))\n","                \n","        #Build gradient functions for desired output channels.\n","        self.get_gradients = {}\n","        if verbose: print(\"Building gradient functions\")\n","        \n","        # Evaluate over all requested channels.\n","        for c in self.outchannels:\n","            # Get tensor that calculates gradient\n","            if K.backend() == \"tensorflow\":\n","                gradients = self.model.optimizer.get_gradients(self.model.output[:, c], self.model.input)\n","            if K.backend() == \"theano\":\n","                gradients = self.model.optimizer.get_gradients(self.model.output[:, c].sum(), self.model.input)\n","                \n","            # Build computational graph that computes the tensors given inputs\n","            self.get_gradients[c] = K.function(inputs=self.input_tensors, outputs=gradients)\n","            \n","            # This takes a lot of time for a big model with many tasks.\n","            # So lets print the progress.\n","            if verbose:\n","                sys.stdout.write('\\r')\n","                sys.stdout.write(\"Progress: \"+str(int((c+1)*1.0/len(self.outchannels)*1000)*1.0/10)+\"%\")\n","                sys.stdout.flush()\n","        # Done\n","        if verbose: print(\"\\nDone.\")\n","            \n","                \n","    '''\n","    Input: sample to explain, channel to explain\n","    Optional inputs:\n","        - reference: reference values (defaulted to 0s).\n","        - steps: # steps from reference values to the actual sample (defualted to 50).\n","    Output: list of numpy arrays to integrated over.\n","    '''\n","    def explain(self, sample, outc=0, reference=False, num_steps=5, verbose=0):\n","        \n","        # Each element for each input stream.\n","        samples = []\n","        numsteps = []\n","        step_sizes = []\n","        \n","        # If multiple inputs are present, feed them as list of np arrays. \n","        if isinstance(sample, list):\n","            #If reference is present, reference and sample size need to be equal.\n","            if reference != False: \n","                assert len(sample) == len(reference)\n","            for i in range(len(sample)):\n","                if reference == False:\n","                    _output = integrated_gradients.linearly_interpolate(sample[i], False, num_steps)\n","                else:\n","                    _output = integrated_gradients.linearly_interpolate(sample[i], reference[i], num_steps)\n","                samples.append(_output[0])\n","                numsteps.append(_output[1])\n","                step_sizes.append(_output[2])\n","        \n","        # Or you can feed just a single numpy arrray. \n","        elif isinstance(sample, np.ndarray):\n","            _output = integrated_gradients.linearly_interpolate(sample, reference, num_steps)\n","            samples.append(_output[0])\n","            numsteps.append(_output[1])\n","            step_sizes.append(_output[2])\n","            \n","        # Desired channel must be in the list of outputchannels\n","        assert outc in self.outchannels\n","        if verbose: print(\"Explaning the \"+str(self.outchannels[outc])+\"th output.\")\n","            \n","        # For tensorflow backend\n","        _input = []\n","        for s in samples:\n","            _input.append(s)\n","        _input.append(0)\n","        print(len(_input))\n","\n","        if K.backend() == \"tensorflow\": \n","            gradients = self.get_gradients[outc](_input)\n","        elif K.backend() == \"theano\":\n","            gradients = self.get_gradients[outc](_input)\n","            if len(self.model.inputs) == 1:\n","                gradients = [gradients]\n","\n","        explanation = []\n","        for i in range(len(gradients)):\n","            _temp = np.sum(gradients[i], axis=0)\n","            explanation.append(np.multiply(_temp, step_sizes[i]))\n","           \n","        # Format the return values according to the input sample.\n","        if isinstance(sample, list):\n","            return explanation\n","        elif isinstance(sample, np.ndarray):\n","            return explanation[0]\n","        return -1\n","\n","    \n","    '''\n","    Input: numpy array of a sample\n","    Optional inputs:\n","        - reference: reference values (defaulted to 0s).\n","        - steps: # steps from reference values to the actual sample.\n","    Output: list of numpy arrays to integrate over.\n","    '''\n","    @staticmethod\n","    def linearly_interpolate(sample, reference=False, num_steps=50):\n","        # Use default reference values if reference is not specified\n","        if reference is False: reference = np.zeros(sample.shape);\n","\n","        # Reference and sample shape needs to match exactly\n","        assert sample.shape == reference.shape\n","\n","        # Calcuated stepwise difference from reference to the actual sample.\n","        ret = np.zeros(tuple([num_steps] +[i for i in sample.shape]))\n","        for s in range(num_steps):\n","            ret[s] = reference+(sample-reference)*(s*1.0/num_steps)\n","\n","        return ret, num_steps, (sample-reference)*(1.0/num_steps)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"akL9HXw1H-sC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598667489089,"user_tz":240,"elapsed":32723,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}}},"source":["# Load the predictor trained by classify.ipynb\n","from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.layers import Input\n","sequential_model = load_model('predictor.h5')\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTlSprxVFaWf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"error","timestamp":1598667611105,"user_tz":240,"elapsed":154733,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}},"outputId":"1fa86c1d-179a-42ab-9ba4-7a55ff685efb"},"source":["# Explanation code. Extremely computationally expensive.\n","# Num_steps may have to be lowered even further if it won't run on your computer\n","# The low num_steps may be a cause of the blocky artifacts as well.\n","# (as the name suggests, the integrated_gradients is actually a definite integral\n","# so more steps should be more accurate)\n","\n","explainer = integrated_gradients(sequential_model)#model)\n","explained = []\n","for i in all_brains:\n","  explained.append(explainer.explain(i, num_steps=5)) #If the ordinary session has enough RAM, the TPU will work to run this i think. but the GPU will crash :("],"execution_count":8,"outputs":[{"output_type":"stream","text":["Evaluated output channel (0-based index): All\n","Building gradient functions\n","\rProgress: 100.0%\n","Done.\n","2\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-93dd6e503aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mexplained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_brains\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mexplained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#If the ordinary session has enough RAM, the TPU will work to run this i think. but the GPU will crash :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-7dd479affa62>\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, sample, outc, reference, num_steps, verbose)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"theano\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3824\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3825\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"-3-f590ythYQ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1598667611100,"user_tz":240,"elapsed":154723,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}}},"source":["# Plot sagittal slice of these explained images\n","import matplotlib.pyplot as plt\n","for i, _ in enumerate(explained):\n","  plt.imshow(explained[i][40, :, :, 0]**2, cmap='Reds', alpha=0.7)\n","  plt.imshow(all_brains[i][40,:,:,0], cmap='Greys', alpha=0.5)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11_LsWxIx4SY","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1598667611102,"user_tz":240,"elapsed":154718,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}}},"source":["# Load explanations+possibly downsampled outputs to output files\n","# nibabel naturally shifts images upon loading (I think), so even if you don't downsample\n","# you'll have to rely on this code\n","\n","if not os.path.exists('brain_samples'):\n","  os.mkdir('brain_samples')\n","if not os.path.exists('heatmaps'):\n","  os.mkdir('heatmaps')\n","for i, brain in enumerate(titles):\n","  print(brain)\n","  img_loaded = nb.load('structural_brains/' +brain)\n","  ni_img = nb.Nifti1Image(explained[i]**2, img_loaded.affine)\n","  nb.save(ni_img, 'heatmaps/heatmap'+str(i)+'.nii.gz')\n","\n","  ni_img = nb.Nifti1Image(all_brains[i], img_loaded.affine)\n","  nb.save(ni_img, 'brain_samples/brain_sample' + str(i) +'.nii.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_72zubNpk6lu","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1598667611103,"user_tz":240,"elapsed":154712,"user":{"displayName":"Matthew So","photoUrl":"","userId":"18273672785190648211"}}},"source":[""],"execution_count":null,"outputs":[]}]}